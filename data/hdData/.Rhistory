proxy.list = emp.cov.names,
nSim = nSim,
intermediate_dir = intermediate_dir) {
print(paste("Simulating iteration:", i))
plasmodeData.i <- plyr::join(x = data.frame(idx = plasmode.data[,i],
EVENT = plasmode.data[,i + nSim]),
y = analytic.data, by = "idx", type = "left")
plasmodeData.i$outcome <- plasmodeData.i$EVENT
plasmodeData.i$EVENT <- NULL
plasmodeData.i$id <- make_ids_unique(plasmodeData.i$id)
saveRDS(plasmodeData.i, file = paste0(intermediate_dir, "/data_", i, ".rds"))
return(plasmodeData.i)
}
# Initialize the cluster
no_cores <- detectCores() - 2
cl <- makeCluster(no_cores)
print(paste("Number of cores:", no_cores))
# Export necessary variables and functions to the cluster
clusterExport(cl, varlist = c("simulate", "simdata", "full.data", "demovars",
"labvars.original", "emp.cov.names", "nSim",
"make_ids_unique", "intermediate_dir"))
# Load necessary libraries on each worker node
clusterEvalQ(cl, {
library(dplyr)
library(Plasmode)
library(plyr)
})
# Initialize the progress bar correctly
progress_bar <- progress::progress_bar$new(total = nSim)
# Wrapper to update the progress bar in the main thread
simulate_with_progress <- function(i) {
res <- clusterCall(cl, simulate, i, simdata, full.data, demovars, labvars.original, emp.cov.names, nSim, intermediate_dir)
progress_bar$tick()
return(res[[1]])
}
# Use a loop to run the simulations and update the progress bar in the main thread
results <- tryCatch({
lapply(43:nSim, simulate_with_progress)
}, error = function(e) {
print(paste("Error in lapply:", e))
stopCluster(cl)  # Ensure the cluster is stopped in case of error
NULL
})
setwd("E:/GitHub/PlasmodeSim/data/hdData/")
require(Plasmode)
require(dplyr)
library(parallel)
library(pbapply)
library(progress)
library(plyr)
make_ids_unique <- function(ids) {
dup_ids <- ids[duplicated(ids) | duplicated(ids, fromLast = TRUE)]
unique_dup_ids <- unique(dup_ids)
for (id in unique_dup_ids) {
suffix <- 1
indices <- which(ids == id)
for (index in indices) {
ids[index] <- paste0(ids[index], ".", suffix)
suffix <- suffix + 1
}
}
return(ids)
}
load(file = "data/plasmode_outcome_rare.RData")
subscript <- ""
base_dir <- "data"
intermediate_dir <- paste0(base_dir, "/scenario", subscript)
dir.create(base_dir, showWarnings = FALSE)
dir.create(intermediate_dir, showWarnings = FALSE)
nSim <- 1000
simulate <- function(i, plasmode.data = simdata,
analytic.data = full.data,
demovars = demovars,
lab.list = labvars.original,
proxy.list = emp.cov.names,
nSim = nSim,
intermediate_dir = intermediate_dir) {
plasmodeData.i <- plyr::join(x = data.frame(idx = plasmode.data[,i],
EVENT = plasmode.data[,i + nSim]),
y = analytic.data, by = "idx", type = "left")
plasmodeData.i$outcome <- plasmodeData.i$EVENT
plasmodeData.i$EVENT <- NULL
plasmodeData.i$id <- make_ids_unique(plasmodeData.i$id)
saveRDS(plasmodeData.i, file = paste0(intermediate_dir, "/data_", i, ".rds"))
return(plasmodeData.i)
}
# Initialize the cluster
no_cores <- detectCores() - 2
cl <- makeCluster(no_cores)
print(paste("Number of cores:", no_cores))
# Export necessary variables and functions to the cluster
clusterExport(cl, varlist = c("simulate", "simdata", "full.data", "demovars",
"labvars.original", "emp.cov.names", "nSim",
"make_ids_unique", "intermediate_dir"))
# Load necessary libraries on each worker node
clusterEvalQ(cl, {
library(dplyr)
library(Plasmode)
library(plyr)
})
# Initialize the progress bar correctly
progress_bar <- progress::progress_bar$new(total = nSim)
# Wrapper to update the progress bar in the main thread
simulate_with_progress <- function(i) {
res <- simulate(i, simdata, full.data, demovars, labvars.original, emp.cov.names, nSim, intermediate_dir)
progress_bar$tick()
return(res)
}
# Use parLapply to run the simulations in parallel and update the progress bar
results <- tryCatch({
parLapply(cl, 72:nSim, simulate_with_progress)
}, error = function(e) {
print(paste("Error in parLapply:", e))
stopCluster(cl)  # Ensure the cluster is stopped in case of error
NULL
})
# Stop the cluster
stopCluster(cl)
setwd("E:/GitHub/PlasmodeSim/data/hdData/")
require(Plasmode)
require(dplyr)
library(parallel)
library(pbapply)
library(progress)
library(plyr)
make_ids_unique <- function(ids) {
dup_ids <- ids[duplicated(ids) | duplicated(ids, fromLast = TRUE)]
unique_dup_ids <- unique(dup_ids)
for (id in unique_dup_ids) {
suffix <- 1
indices <- which(ids == id)
for (index in indices) {
ids[index] <- paste0(ids[index], ".", suffix)
suffix <- suffix + 1
}
}
return(ids)
}
load(file = "data/plasmode_outcome_rare.RData")
subscript <- ""
base_dir <- "data"
intermediate_dir <- paste0(base_dir, "/scenario", subscript)
dir.create(base_dir, showWarnings = FALSE)
dir.create(intermediate_dir, showWarnings = FALSE)
nSim <- 1000
simulate <- function(i, plasmode.data = simdata,
analytic.data = full.data,
demovars = demovars,
lab.list = labvars.original,
proxy.list = emp.cov.names,
nSim = nSim,
intermediate_dir = intermediate_dir) {
plasmodeData.i <- plyr::join(x = data.frame(idx = plasmode.data[,i],
EVENT = plasmode.data[,i + nSim]),
y = analytic.data, by = "idx", type = "left")
plasmodeData.i$outcome <- plasmodeData.i$EVENT
plasmodeData.i$EVENT <- NULL
plasmodeData.i$id <- make_ids_unique(plasmodeData.i$id)
saveRDS(plasmodeData.i, file = paste0(intermediate_dir, "/data_", i, ".rds"))
return(plasmodeData.i)
}
# Initialize the cluster
no_cores <- detectCores() - 2
cl <- makeCluster(no_cores)
print(paste("Number of cores:", no_cores))
# Export necessary variables and functions to the cluster
clusterExport(cl, varlist = c("simulate", "simdata", "full.data", "demovars",
"labvars.original", "emp.cov.names", "nSim",
"make_ids_unique", "intermediate_dir"))
# Load necessary libraries on each worker node
clusterEvalQ(cl, {
library(dplyr)
library(Plasmode)
library(plyr)
})
# Initialize the progress bar correctly
progress_bar <- progress::progress_bar$new(total = nSim)
# Use parLapply to run the simulations in parallel
results <- tryCatch({
parLapply(cl, 72:nSim, function(i) {
result <- simulate(i, simdata, full.data, demovars, labvars.original, emp.cov.names, nSim, intermediate_dir)
# Update progress bar on the main thread
progress_bar$tick()
return(result)
})
}, error = function(e) {
print(paste("Error in parLapply:", e))
stopCluster(cl)  # Ensure the cluster is stopped in case of error
NULL
})
# Stop the cluster
stopCluster(cl)
setwd("E:/GitHub/PlasmodeSim/data/hdData/")
require(Plasmode)
require(dplyr)
library(parallel)
library(pbapply)
library(progress)
library(plyr)
make_ids_unique <- function(ids) {
dup_ids <- ids[duplicated(ids) | duplicated(ids, fromLast = TRUE)]
unique_dup_ids <- unique(dup_ids)
for (id in unique_dup_ids) {
suffix <- 1
indices <- which(ids == id)
for (index in indices) {
ids[index] <- paste0(ids[index], ".", suffix)
suffix <- suffix + 1
}
}
return(ids)
}
load(file = "data/plasmode_outcome_rare.RData")
subscript <- ""
base_dir <- "data"
intermediate_dir <- paste0(base_dir, "/scenario", subscript)
dir.create(base_dir, showWarnings = FALSE)
dir.create(intermediate_dir, showWarnings = FALSE)
nSim <- 1000
simulate <- function(i, plasmode.data, analytic.data, demovars, lab.list, proxy.list, nSim, intermediate_dir) {
plasmodeData.i <- plyr::join(x = data.frame(idx = plasmode.data[,i],
EVENT = plasmode.data[,i + nSim]),
y = analytic.data, by = "idx", type = "left")
plasmodeData.i$outcome <- plasmodeData.i$EVENT
plasmodeData.i$EVENT <- NULL
plasmodeData.i$id <- make_ids_unique(plasmodeData.i$id)
saveRDS(plasmodeData.i, file = paste0(intermediate_dir, "/data_", i, ".rds"))
return(plasmodeData.i)
}
# Initialize the cluster
no_cores <- detectCores() - 2
cl <- makeCluster(no_cores)
print(paste("Number of cores:", no_cores))
# Export necessary variables and functions to the cluster
clusterExport(cl, varlist = c("simulate", "simdata", "full.data", "demovars",
"labvars.original", "emp.cov.names", "nSim",
"make_ids_unique", "intermediate_dir"))
# Load necessary libraries on each worker node
clusterEvalQ(cl, {
library(dplyr)
library(Plasmode)
library(plyr)
})
# Use pbapply to run the simulations in parallel with a progress bar
results <- tryCatch({
pblapply(73:nSim, function(i) {
simulate(i, simdata, full.data, demovars, labvars.original, emp.cov.names, nSim, intermediate_dir)
}, cl = cl)
}, error = function(e) {
print(paste("Error in parLapply:", e))
stopCluster(cl)  # Ensure the cluster is stopped in case of error
NULL
})
# Stop the cluster
stopCluster(cl)
print("Simulation completed.")
setwd("E:/GitHub/PlasmodeSim/data/hdData/")
require(Plasmode)
require(dplyr)
library(parallel)
library(pbapply)
library(progress)
library(plyr)
make_ids_unique <- function(ids) {
dup_ids <- ids[duplicated(ids) | duplicated(ids, fromLast = TRUE)]
unique_dup_ids <- unique(dup_ids)
for (id in unique_dup_ids) {
suffix <- 1
indices <- which(ids == id)
for (index in indices) {
ids[index] <- paste0(ids[index], ".", suffix)
suffix <- suffix + 1
}
}
return(ids)
}
load(file = "data/plasmode_exposure_rare.RData")
subscript <- "ER"
base_dir <- "data"
intermediate_dir <- paste0(base_dir, "/scenario", subscript)
dir.create(base_dir, showWarnings = FALSE)
dir.create(intermediate_dir, showWarnings = FALSE)
nSim <- 1000
simulate <- function(i, plasmode.data, analytic.data, demovars, lab.list, proxy.list, nSim, intermediate_dir) {
plasmodeData.i <- plyr::join(x = data.frame(idx = plasmode.data[,i],
EVENT = plasmode.data[,i + nSim]),
y = analytic.data, by = "idx", type = "left")
plasmodeData.i$outcome <- plasmodeData.i$EVENT
plasmodeData.i$EVENT <- NULL
plasmodeData.i$id <- make_ids_unique(plasmodeData.i$id)
saveRDS(plasmodeData.i, file = paste0(intermediate_dir, "/data_", i, ".rds"))
return(plasmodeData.i)
}
# Initialize the cluster
no_cores <- detectCores() - 2
cl <- makeCluster(no_cores)
print(paste("Number of cores:", no_cores))
# Export necessary variables and functions to the cluster
clusterExport(cl, varlist = c("simulate", "simdata", "full.data", "demovars",
"labvars.original", "emp.cov.names", "nSim",
"make_ids_unique", "intermediate_dir"))
# Load necessary libraries on each worker node
clusterEvalQ(cl, {
library(dplyr)
library(Plasmode)
library(plyr)
})
# Use pbapply to run the simulations in parallel with a progress bar
results <- tryCatch({
pblapply(73:nSim, function(i) {
simulate(i, simdata, full.data, demovars, labvars.original, emp.cov.names, nSim, intermediate_dir)
}, cl = cl)
}, error = function(e) {
print(paste("Error in parLapply:", e))
stopCluster(cl)  # Ensure the cluster is stopped in case of error
NULL
})
# Stop the cluster
stopCluster(cl)
print("Simulation completed.")
setwd("E:/GitHub/PlasmodeSim/data/hdData/")
require(Plasmode)
require(dplyr)
library(parallel)
library(pbapply)
library(progress)
library(plyr)
make_ids_unique <- function(ids) {
dup_ids <- ids[duplicated(ids) | duplicated(ids, fromLast = TRUE)]
unique_dup_ids <- unique(dup_ids)
for (id in unique_dup_ids) {
suffix <- 1
indices <- which(ids == id)
for (index in indices) {
ids[index] <- paste0(ids[index], ".", suffix)
suffix <- suffix + 1
}
}
return(ids)
}
load(file = "data/plasmode.RData")
subscript <- ""
base_dir <- "data"
intermediate_dir <- paste0(base_dir, "/scenario", subscript)
dir.create(base_dir, showWarnings = FALSE)
dir.create(intermediate_dir, showWarnings = FALSE)
nSim <- 1000
simulate <- function(i, plasmode.data, analytic.data, demovars, lab.list, proxy.list, nSim, intermediate_dir) {
plasmodeData.i <- plyr::join(x = data.frame(idx = plasmode.data[,i],
EVENT = plasmode.data[,i + nSim]),
y = analytic.data, by = "idx", type = "left")
plasmodeData.i$outcome <- plasmodeData.i$EVENT
plasmodeData.i$EVENT <- NULL
plasmodeData.i$id <- make_ids_unique(plasmodeData.i$id)
saveRDS(plasmodeData.i, file = paste0(intermediate_dir, "/data_", i, ".rds"))
return(plasmodeData.i)
}
# Initialize the cluster
no_cores <- detectCores() - 2
cl <- makeCluster(no_cores)
print(paste("Number of cores:", no_cores))
# Export necessary variables and functions to the cluster
clusterExport(cl, varlist = c("simulate", "simdata", "full.data", "demovars",
"labvars.original", "emp.cov.names", "nSim",
"make_ids_unique", "intermediate_dir"))
# Load necessary libraries on each worker node
clusterEvalQ(cl, {
library(dplyr)
library(Plasmode)
library(plyr)
})
# Use pbapply to run the simulations in parallel with a progress bar
results <- tryCatch({
pblapply(73:nSim, function(i) {
simulate(i, simdata, full.data, demovars, labvars.original, emp.cov.names, nSim, intermediate_dir)
}, cl = cl)
}, error = function(e) {
print(paste("Error in parLapply:", e))
stopCluster(cl)  # Ensure the cluster is stopped in case of error
NULL
})
# Stop the cluster
stopCluster(cl)
print("Simulation completed.")
setwd("E:/GitHub/PlasmodeSim/data/hdData/")
require(Plasmode)
require(dplyr)
library(parallel)
library(pbapply)
library(progress)
library(plyr)
make_ids_unique <- function(ids) {
dup_ids <- ids[duplicated(ids) | duplicated(ids, fromLast = TRUE)]
unique_dup_ids <- unique(dup_ids)
for (id in unique_dup_ids) {
suffix <- 1
indices <- which(ids == id)
for (index in indices) {
ids[index] <- paste0(ids[index], ".", suffix)
suffix <- suffix + 1
}
}
return(ids)
}
load(file = "data/plasmode.RData")
subscript <- ""
base_dir <- "data"
intermediate_dir <- paste0(base_dir, "/scenario", subscript)
dir.create(base_dir, showWarnings = FALSE)
dir.create(intermediate_dir, showWarnings = FALSE)
nSim <- 1000
simulate <- function(i, plasmode.data, analytic.data, demovars, lab.list, proxy.list, nSim, intermediate_dir) {
plasmodeData.i <- plyr::join(x = data.frame(idx = plasmode.data[,i],
EVENT = plasmode.data[,i + nSim]),
y = analytic.data, by = "idx", type = "left")
plasmodeData.i$outcome <- plasmodeData.i$EVENT
plasmodeData.i$EVENT <- NULL
plasmodeData.i$id <- make_ids_unique(plasmodeData.i$id)
saveRDS(plasmodeData.i, file = paste0(intermediate_dir, "/data_", i, ".rds"))
return(plasmodeData.i)
}
# Initialize the cluster
no_cores <- detectCores() - 2
cl <- makeCluster(no_cores)
print(paste("Number of cores:", no_cores))
# Export necessary variables and functions to the cluster
clusterExport(cl, varlist = c("simulate", "simdata", "full.data", "demovars",
"labvars.original", "emp.cov.names", "nSim",
"make_ids_unique", "intermediate_dir"))
# Load necessary libraries on each worker node
clusterEvalQ(cl, {
library(dplyr)
library(Plasmode)
library(plyr)
})
# Use pbapply to run the simulations in parallel with a progress bar
results <- tryCatch({
pblapply(1:72, function(i) {
simulate(i, simdata, full.data, demovars, labvars.original, emp.cov.names, nSim, intermediate_dir)
}, cl = cl)
}, error = function(e) {
print(paste("Error in parLapply:", e))
stopCluster(cl)  # Ensure the cluster is stopped in case of error
NULL
})
# Stop the cluster
stopCluster(cl)
print("Simulation completed.")
setwd("E:/GitHub/PlasmodeSim/data/hdData/")
require(Plasmode)
require(dplyr)
library(parallel)
library(pbapply)
library(progress)
library(plyr)
make_ids_unique <- function(ids) {
dup_ids <- ids[duplicated(ids) | duplicated(ids, fromLast = TRUE)]
unique_dup_ids <- unique(dup_ids)
for (id in unique_dup_ids) {
suffix <- 1
indices <- which(ids == id)
for (index in indices) {
ids[index] <- paste0(ids[index], ".", suffix)
suffix <- suffix + 1
}
}
return(ids)
}
load(file = "data/plasmode_exposure_rare.RData")
subscript <- "ER"
base_dir <- "data"
intermediate_dir <- paste0(base_dir, "/scenario", subscript)
dir.create(base_dir, showWarnings = FALSE)
dir.create(intermediate_dir, showWarnings = FALSE)
nSim <- 1000
simulate <- function(i, plasmode.data, analytic.data, demovars, lab.list, proxy.list, nSim, intermediate_dir) {
plasmodeData.i <- plyr::join(x = data.frame(idx = plasmode.data[,i],
EVENT = plasmode.data[,i + nSim]),
y = analytic.data, by = "idx", type = "left")
plasmodeData.i$outcome <- plasmodeData.i$EVENT
plasmodeData.i$EVENT <- NULL
plasmodeData.i$id <- make_ids_unique(plasmodeData.i$id)
saveRDS(plasmodeData.i, file = paste0(intermediate_dir, "/data_", i, ".rds"))
return(plasmodeData.i)
}
# Initialize the cluster
no_cores <- detectCores() - 2
cl <- makeCluster(no_cores)
print(paste("Number of cores:", no_cores))
# Export necessary variables and functions to the cluster
clusterExport(cl, varlist = c("simulate", "simdata", "full.data", "demovars",
"labvars.original", "emp.cov.names", "nSim",
"make_ids_unique", "intermediate_dir"))
# Load necessary libraries on each worker node
clusterEvalQ(cl, {
library(dplyr)
library(Plasmode)
library(plyr)
})
# Use pbapply to run the simulations in parallel with a progress bar
results <- tryCatch({
pblapply(1:73, function(i) {
simulate(i, simdata, full.data, demovars, labvars.original, emp.cov.names, nSim, intermediate_dir)
}, cl = cl)
}, error = function(e) {
print(paste("Error in parLapply:", e))
stopCluster(cl)  # Ensure the cluster is stopped in case of error
NULL
})
# Stop the cluster
stopCluster(cl)
print("Simulation completed.")
